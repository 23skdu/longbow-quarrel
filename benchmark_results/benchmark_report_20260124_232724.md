# LLM Performance Benchmark Report

**Generated:** Sat Jan 24 23:29:08 PST 2026  
**Model:** Mistral 7B (4.3GB GGUF)  
**Test Prompt:** "The quick brown fox jumps over the lazy dog"  
**Tokens Generated:** 100  
**Iterations:** 3  

## System Information

- **OS:** Darwin 25.2.0
- **Architecture:** arm64
- **Memory:** 36.0 GB
- **Go Version:** go version go1.25.6 darwin/arm64

## Benchmark Results

### longbow-quarrel (Metal GPU)

| Metric | Tokens/sec |
|--------|-----------|
| Average | [0;34mRunning longbow-quarrel (Metal)...[0m
  Iteration 1/3:   2.60 tokens/sec (38.00s)
  Iteration 2/3:   3.10 tokens/sec (32.00s)
  Iteration 3/3:   3.10 tokens/sec (32.00s)
  Average: 2.94 tokens/sec
  Min:  tokens/sec
  Max: 3.1 tokens/sec

2.94 |
| Minimum | [0;34mRunning longbow-quarrel (Metal)...[0m
  Iteration 1/3:   2.60 tokens/sec (38.00s)
  Iteration 2/3:   3.10 tokens/sec (32.00s)
  Iteration 3/3:   3.10 tokens/sec (32.00s)
  Average: 2.94 tokens/sec
  Min:  tokens/sec
  Max: 3.1 tokens/sec |
| Maximum | [0;34mRunning longbow-quarrel (Metal)...[0m
  Iteration 1/3:   2.60 tokens/sec (38.00s)
  Iteration 2/3:   3.10 tokens/sec (32.00s)
  Iteration 3/3:   3.10 tokens/sec (32.00s)
  Average: 2.94 tokens/sec
  Min:  tokens/sec
  Max: 3.1 tokens/sec

3.1 |

### llama.cpp

> **Note:** llama.cpp benchmarking not implemented in this script
> 
> Manual command:
> ```bash
> ./llama.cpp/main -m "/Users/rsd/.ollama/models/blobs/sha256-f5074b1221da0f5a2910d33b642efa5b9eb58cfdddca1c79e16d7ad28aa2b31f" -p "The quick brown fox jumps over the lazy dog" -n 100 --color
> ```

## Analysis

### Performance Summary

- **longbow-quarrel Performance:** [0;34mRunning longbow-quarrel (Metal)...[0m
  Iteration 1/3:   2.60 tokens/sec (38.00s)
  Iteration 2/3:   3.10 tokens/sec (32.00s)
  Iteration 3/3:   3.10 tokens/sec (32.00s)
  Average: 2.94 tokens/sec
  Min:  tokens/sec
  Max: 3.1 tokens/sec

2.94 tokens/sec
- **Acceleration:** Metal GPU acceleration with custom kernels
- **Model Size:** 7B parameters (Mistral architecture)

### Observations

1. **Metal Backend**: Successfully utilizing Apple Silicon GPU
2. **Memory Usage**: Efficient KV cache allocation (32 MB)
3. **Kernel Optimization**: Custom Metal kernels for Llama operations
4. **Quantization**: Mixed F16/FP32 precision for optimal performance

## Technical Details

### longbow-quarrel Architecture

- **Framework**: Go + Metal compute shaders
- **Precision**: Mixed precision (F16/F32)
- **Memory Management**: Tensor pooling with global budget
- **Kernel Fusion**: RMSNorm+Linear, attention optimizations
- **Thread Safety**: Asynchronous GPU dispatch

### Model Configuration

- **Architecture**: Llama 3 / Mistral compatible
- **Attention**: Grouped Query Attention (GQA)
- **Positional**: RoPE embeddings
- **Activation**: SwiGLU
- **Layers**: 32
- **Hidden Size**: 4096
- **Heads**: 32 (8 KV heads)

---

*Report generated by longbow-quarrel benchmark suite*
